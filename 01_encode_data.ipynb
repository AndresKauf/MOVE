{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode data\n",
    "\n",
    "This notebook runs part of the Multi-Omics Variational autoEncoder (MOVE) framework for using the structure the VAE has identified for extracting categorical data assositions across all continuous datasets. In the MOVE paper we used it for identifiying drug assosiations in clinical and multi-omics data. This part is a guide for encoding the data that can be used as input in MOVE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions\n",
    "from hydra import initialize, compose\n",
    "\n",
    "from move.utils.data_utils import read_ids, generate_file, merge_configs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook merges user-defined configs in data.yaml file with default configs and override it. Then reads the needed variables.  \\\n",
    "For encoding the data you need to have each dataset/data type in a format for N x M, where N is the numer of samples/individuals and M is the number of features. For using the dataset specific weighting in the training of the VAE you need to process the datasets individually or split them when you read them in. The continuous data is z-score normalised and the categorical data is one-hot encoded. Below is an example of processing a continuous and categorical datasets. To ensure the correct order the ID's are used for sorting the data accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding the default config with configs from data.yaml\n",
      "\n",
      "Configuration used: \n",
      "---\n",
      "data:\n",
      "  user_config: data.yaml\n",
      "  na_value: na\n",
      "  raw_data_path: data/\n",
      "  interim_data_path: interim_data/\n",
      "  processed_data_path: processed_data/\n",
      "  version: v1\n",
      "  ids_file_name: baseline_ids.txt\n",
      "  ids_has_header: false\n",
      "  ids_colname: 0\n",
      "  categorical_inputs:\n",
      "  - name: diabetes_genotypes\n",
      "    weight: 1\n",
      "  - name: baseline_drugs\n",
      "    weight: 1\n",
      "  - name: baseline_categorical\n",
      "    weight: 1\n",
      "  continuous_inputs:\n",
      "  - name: baseline_continuous\n",
      "    weight: 2\n",
      "  - name: baseline_transcriptomics\n",
      "    weight: 1\n",
      "  - name: baseline_diet_wearables\n",
      "    weight: 1\n",
      "  - name: baseline_proteomic_antibodies\n",
      "    weight: 1\n",
      "  - name: baseline_target_metabolomics\n",
      "    weight: 1\n",
      "  - name: baseline_untarget_metabolomics\n",
      "    weight: 1\n",
      "  - name: baseline_metagenomics\n",
      "    weight: 1\n",
      "  data_of_interest: baseline_drugs\n",
      "  categorical_names: ${names:${data.categorical_inputs}}\n",
      "  continuous_names: ${names:${data.continuous_inputs}}\n",
      "  categorical_weights: ${weights:${data.categorical_inputs}}\n",
      "  continuous_weights: ${weights:${data.continuous_inputs}}\n",
      "  data_features_to_visualize_notebook4:\n",
      "  - drug_1\n",
      "  - clinical_continuous_2\n",
      "  - clinical_continuous_3\n",
      "  write_omics_results_notebook5:\n",
      "  - baseline_target_metabolomics\n",
      "  - baseline_untarget_metabolomics\n",
      "---\n",
      "\n",
      "Encoding categorical data\n",
      "<class 'list'>\n",
      "  Encoded diabetes_genotypes\n",
      "<class 'list'>\n",
      "  Encoded baseline_drugs\n",
      "<class 'list'>\n",
      "  Encoded baseline_categorical\n",
      "Encoding continuous data\n",
      "<class 'list'>\n",
      "  Encoded baseline_continuous\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_42386/4697057.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_42386/4697057.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(base_config)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Encoding continuous data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcon_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontinuous_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mgenerate_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'continuous'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterim_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'  Encoded {con_data}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/move2/MOVE/src/move/utils/data_utils.py\u001b[0m in \u001b[0;36mgenerate_file\u001b[0;34m(var_type, raw_data_path, interim_data_path, headers_path, data_type, ids, na)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;31m# Preparing the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m     \u001b[0mraw_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m     \u001b[0msorted_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msort_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/move2/MOVE/src/move/utils/data_utils.py\u001b[0m in \u001b[0;36mread_files\u001b[0;34m(path, data_type, na)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvals\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initializing the default config \n",
    "with initialize(version_base=None, config_path=\"src/move/conf\"):\n",
    "    base_config = compose(config_name=\"main\")\n",
    "\n",
    "def main(base_config=base_config):\n",
    "    \n",
    "    # Overriding base_config with the user defined configs.\n",
    "    cfg = merge_configs(base_config=base_config, \n",
    "                        config_types=['data'])\n",
    "    \n",
    "    # Getting the variables used in the notebook\n",
    "    raw_data_path = cfg.data.raw_data_path\n",
    "    interim_data_path = cfg.data.interim_data_path\n",
    "    headers_path = cfg.data.headers_path\n",
    "    \n",
    "    ids_file_name = cfg.data.ids_file_name\n",
    "    ids_has_header = cfg.data.ids_has_header\n",
    "    ids_colname = cfg.data.ids_colname\n",
    "    \n",
    "    na_encoding = cfg.data.na_value\n",
    "    categorical_names = cfg.data.categorical_names\n",
    "    continuous_names = cfg.data.continuous_names    \n",
    "    \n",
    "    # Reading ids \n",
    "    ids = read_ids(raw_data_path, ids_file_name, ids_colname, ids_has_header)\n",
    "\n",
    "    # Encoding categorical data\n",
    "    print('Encoding categorical data')\n",
    "    for cat_data in categorical_names:\n",
    "        generate_file('categorical', raw_data_path, interim_data_path, headers_path, cat_data, ids, na_encoding)\n",
    "        print(f'  Encoded {cat_data}')\n",
    "    \n",
    "    # Encoding continuous data \n",
    "    print('Encoding continuous data')\n",
    "    for con_data in continuous_names:\n",
    "        generate_file('continuous', raw_data_path, interim_data_path, headers_path, con_data, ids, na_encoding)    \n",
    "        print(f'  Encoded {con_data}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
