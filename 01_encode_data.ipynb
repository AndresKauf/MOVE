{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode data\n",
    "\n",
    "This notebook runs part of the Multi-Omics Variational autoEncoder (MOVE) framework for using the structure the VAE has identified for extracting categorical data assositions across all continuous datasets. In the MOVE paper we used it for identifiying drug assosiations in clinical and multi-omics data. This part is a guide for encoding the data that can be used as input in MOVE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valentas/move2/MOVE/src/move/training/train.py:16: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"../conf\", config_name=\"main\")\n"
     ]
    }
   ],
   "source": [
    "# Import functions\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from move._utils.data_utils import generate_file, merge_configs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For encoding the data you need to have each dataset/data type in a format for N x M, where N is the numer of samples/individuals and M is the number of features. For using the dataset specific weighting in the training of the VAE you need to process the datasets individually or split them when you read them in. The continuous data is z-score normalised and the categorical data is one-hot encoded. Below is an example of processing a continuous dataset and two categorical datasets with different number of categories. To ensure the correct order the ID's are used for sorting the data accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding the default configuration with configuration from data.yaml\n",
      "\n",
      "Configuration used: \n",
      "---\n",
      "data:\n",
      "  user_config: data.yaml\n",
      "  na_value: 'nan'\n",
      "  raw_data_path: data/\n",
      "  interim_data_path: data/\n",
      "  processed_data_path: data/\n",
      "  version: v1\n",
      "  ids_file_name: baseline_ids\n",
      "  categorical_inputs:\n",
      "  - name: diabetes_genotypes\n",
      "    weight: 1\n",
      "  - name: baseline_drugs\n",
      "    weight: 1\n",
      "  - name: baseline_categorical\n",
      "    weight: 1\n",
      "  continuous_inputs:\n",
      "  - name: baseline_continuous\n",
      "    weight: 2\n",
      "  - name: baseline_transcriptomics\n",
      "    weight: 1\n",
      "  - name: baseline_diet_wearables\n",
      "    weight: 1\n",
      "  - name: baseline_proteomic_antibodies\n",
      "    weight: 1\n",
      "  - name: baseline_target_metabolomics\n",
      "    weight: 1\n",
      "  - name: baseline_untarget_metabolomics\n",
      "    weight: 1\n",
      "  - name: baseline_metagenomics\n",
      "    weight: 1\n",
      "  data_of_interest: baseline_drugs\n",
      "  data_features_to_visualize:\n",
      "  - drug_1\n",
      "  - clinical_continuous_2\n",
      "  - clinical_continuous_3\n",
      "  categorical_names: ${names:${data.categorical_inputs}}\n",
      "  continuous_names: ${names:${data.continuous_inputs}}\n",
      "  categorical_weights: ${weights:${data.categorical_inputs}}\n",
      "  continuous_weights: ${weights:${data.continuous_inputs}}\n",
      "---\n",
      "\n",
      "Encoding categorical data\n",
      "  Encoded diabetes_genotypes\n",
      "  Encoded baseline_drugs\n",
      "  Encoded baseline_categorical\n",
      "Encoding continuous data\n",
      "  Encoded baseline_continuous\n",
      "  Encoded baseline_transcriptomics\n",
      "  Encoded baseline_diet_wearables\n",
      "  Encoded baseline_proteomic_antibodies\n",
      "  Encoded baseline_target_metabolomics\n",
      "  Encoded baseline_untarget_metabolomics\n",
      "  Encoded baseline_metagenomics\n"
     ]
    }
   ],
   "source": [
    "# Initializing the default config \n",
    "with initialize(version_base=None, config_path=\"src/move/conf\"):\n",
    "    base_config = compose(config_name=\"main\")\n",
    "\n",
    "def main(base_config=base_config):\n",
    "    \n",
    "    # Merging the user defined data.yaml, model.yaml and tuning_reconstruction.yaml \n",
    "    # with the base_config to override it.\n",
    "    print('Overriding the default configuration with configuration from data.yaml')\n",
    "    cfg = merge_configs(base_config=base_config, \n",
    "                        config_types=['data'])\n",
    "    \n",
    "    # Getting the variables used in the notebook\n",
    "    path = cfg.data.processed_data_path\n",
    "    ids_file_name = cfg.data.ids_file_name\n",
    "    na_encoding = cfg.data.na_value\n",
    "    categorical_names = cfg.data.categorical_names\n",
    "    continuous_names = cfg.data.continuous_names    \n",
    "    \n",
    "    # Encoding categorical data\n",
    "    print('Encoding categorical data')\n",
    "    for cat_data in categorical_names:\n",
    "        generate_file('categorical', path, cat_data, ids_file_name, na_encoding)\n",
    "        print(f'  Encoded {cat_data}')\n",
    "    \n",
    "    # Encoding continuous data \n",
    "    print('Encoding continuous data')\n",
    "    for con_data in continuous_names:\n",
    "        generate_file('continuous', path, con_data, ids_file_name, na_encoding)    \n",
    "        print(f'  Encoded {con_data}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
