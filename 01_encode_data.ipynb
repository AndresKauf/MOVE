{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode data\n",
    "\n",
    "This notebook runs part of the Multi-Omics Variational autoEncoder (MOVE) framework for using the structure the VAE has identified for extracting categorical data assositions across all continuous datasets. In the MOVE paper we used it for identifiying drug assosiations in clinical and multi-omics data. This part is a guide for encoding the data that can be used as input in MOVE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions\n",
    "from hydra import initialize, compose\n",
    "\n",
    "from move.utils.data_utils import read_ids, generate_file, merge_configs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For encoding the data you need to have each dataset/data type in a format for N x M, where N is the numer of samples/individuals and M is the number of features. For using the dataset specific weighting in the training of the VAE you need to process the datasets individually or split them when you read them in. The continuous data is z-score normalised and the categorical data is one-hot encoded. Below is an example of processing a continuous dataset and two categorical datasets with different number of categories. To ensure the correct order the ID's are used for sorting the data accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding the default config with configs from data.yaml\n",
      "\n",
      "Configuration used: \n",
      "---\n",
      "data:\n",
      "  user_config: data.yaml\n",
      "  na_value: na\n",
      "  raw_data_path: data/\n",
      "  interim_data_path: interim_data/\n",
      "  processed_data_path: processed_data/\n",
      "  version: v1\n",
      "  ids_file_name: baseline_ids\n",
      "  ids_has_header: false\n",
      "  ids_colname: 0\n",
      "  categorical_inputs:\n",
      "  - name: diabetes_genotypes\n",
      "    weight: 1\n",
      "  - name: baseline_drugs\n",
      "    weight: 1\n",
      "  - name: baseline_categorical\n",
      "    weight: 1\n",
      "  continuous_inputs:\n",
      "  - name: baseline_continuous\n",
      "    weight: 2\n",
      "  - name: baseline_transcriptomics\n",
      "    weight: 1\n",
      "  - name: baseline_diet_wearables\n",
      "    weight: 1\n",
      "  - name: baseline_proteomic_antibodies\n",
      "    weight: 1\n",
      "  - name: baseline_target_metabolomics\n",
      "    weight: 1\n",
      "  - name: baseline_untarget_metabolomics\n",
      "    weight: 1\n",
      "  - name: baseline_metagenomics\n",
      "    weight: 1\n",
      "  data_of_interest: baseline_drugs\n",
      "  categorical_names: ${names:${data.categorical_inputs}}\n",
      "  continuous_names: ${names:${data.continuous_inputs}}\n",
      "  categorical_weights: ${weights:${data.categorical_inputs}}\n",
      "  continuous_weights: ${weights:${data.continuous_inputs}}\n",
      "  data_features_to_visualize_notebook4:\n",
      "  - drug_1\n",
      "  - clinical_continuous_2\n",
      "  - clinical_continuous_3\n",
      "  write_omics_results_notebook5:\n",
      "  - baseline_target_metabolomics\n",
      "  - baseline_untarget_metabolomics\n",
      "---\n",
      "\n",
      "Encoding categorical data\n",
      "  Encoded diabetes_genotypes\n",
      "  Encoded baseline_drugs\n",
      "  Encoded baseline_categorical\n",
      "Encoding continuous data\n",
      "  Encoded baseline_continuous\n",
      "  Encoded baseline_transcriptomics\n",
      "  Encoded baseline_diet_wearables\n",
      "  Encoded baseline_proteomic_antibodies\n",
      "  Encoded baseline_target_metabolomics\n",
      "  Encoded baseline_untarget_metabolomics\n",
      "  Encoded baseline_metagenomics\n"
     ]
    }
   ],
   "source": [
    "# Initializing the default config \n",
    "with initialize(version_base=None, config_path=\"src/move/conf\"):\n",
    "    base_config = compose(config_name=\"main\")\n",
    "\n",
    "def main(base_config=base_config):\n",
    "    \n",
    "    # Overriding base_config with the user defined configs.\n",
    "    cfg = merge_configs(base_config=base_config, \n",
    "                        config_types=['data'])\n",
    "    \n",
    "    # Getting the variables used in the notebook\n",
    "    raw_data_path = cfg.data.raw_data_path\n",
    "    interim_data_path = cfg.data.interim_data_path\n",
    "    ids_file_name = cfg.data.ids_file_name\n",
    "    ids_has_header = cfg.data.ids_has_header\n",
    "    ids_colname = cfg.data.ids_colname\n",
    "    \n",
    "    na_encoding = cfg.data.na_value\n",
    "    categorical_names = cfg.data.categorical_names\n",
    "    continuous_names = cfg.data.continuous_names    \n",
    "    \n",
    "    # Reading ids \n",
    "    ids = read_ids(raw_data_path, ids_file_name, ids_colname, ids_has_header)\n",
    "\n",
    "    # Encoding categorical data\n",
    "    print('Encoding categorical data')\n",
    "    for cat_data in categorical_names:\n",
    "        generate_file('categorical', raw_data_path, interim_data_path, cat_data, ids, na_encoding)\n",
    "        print(f'  Encoded {cat_data}')\n",
    "    \n",
    "    # Encoding continuous data \n",
    "    print('Encoding continuous data')\n",
    "    for con_data in continuous_names:\n",
    "        generate_file('continuous', raw_data_path, interim_data_path, con_data, ids, na_encoding)    \n",
    "        print(f'  Encoded {con_data}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# raw_data_path='data/'\n",
    "# ids_file_name='baseline_ids'\n",
    "# ids_has_header=True\n",
    "# ids_colname='0'\n",
    "\n",
    "# def read_ids(path, ids_file_name, ids_colname, ids_has_header=True):\n",
    "#     header=0 if ids_has_header else None\n",
    "        \n",
    "#     ids = pd.read_csv(path + f\"{ids_file_name}.txt\", sep='\\t', header=header)\n",
    "#     ids.columns = ids.columns.astype(str)\n",
    "    \n",
    "#     return list(ids[ids_colname])\n",
    "\n",
    "# ids = read_ids(raw_data_path, ids_file_name, ids_colname, ids_has_header)\n",
    "# print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
