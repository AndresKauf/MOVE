{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode data\n",
    "\n",
    "This notebook runs part of the Multi-Omics Variational autoEncoder (MOVE) framework for using the structure the VAE has identified for extracting categorical data assositions across all continuous datasets. In the MOVE paper we used it for identifiying drug assosiations in clinical and multi-omics data. This part is a guide for encoding the data that can be used as input in MOVE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID  metagenomics_1  metagenomics_2  metagenomics_3  metagenomics_4  \\\n",
      "0      0               0               0               0               0   \n",
      "1      1              14               2               0               0   \n",
      "2      2               4               0               0               0   \n",
      "3      3               0               0               0               0   \n",
      "4      4              12               0               0              14   \n",
      "..   ...             ...             ...             ...             ...   \n",
      "784  784               0               0               0              26   \n",
      "785  785               0               0               0               0   \n",
      "786  786              11              10               0               0   \n",
      "787  787               0               3               0               0   \n",
      "788  788              23               0               0               8   \n",
      "\n",
      "     metagenomics_5  metagenomics_6  metagenomics_7  metagenomics_8  \\\n",
      "0                 0              34               0              18   \n",
      "1                 0               0              10               7   \n",
      "2                15              15              20               9   \n",
      "3                 7               0               0               0   \n",
      "4                 0              14               0               9   \n",
      "..              ...             ...             ...             ...   \n",
      "784               0               0              10               0   \n",
      "785               0              24               0               0   \n",
      "786               7               0               0               0   \n",
      "787              19              24              12              13   \n",
      "788               0              15               0               0   \n",
      "\n",
      "     metagenomics_9  ...  metagenomics_1454  metagenomics_1455  \\\n",
      "0                 0  ...                  0                  0   \n",
      "1                 0  ...                 13                 23   \n",
      "2                 0  ...                  6                 27   \n",
      "3                 0  ...                  2                 21   \n",
      "4                 0  ...                 15                  0   \n",
      "..              ...  ...                ...                ...   \n",
      "784              13  ...                  0                  0   \n",
      "785              12  ...                  2                  9   \n",
      "786              15  ...                  0                  0   \n",
      "787               0  ...                 25                 19   \n",
      "788               0  ...                  0                 34   \n",
      "\n",
      "     metagenomics_1456  metagenomics_1457  metagenomics_1458  \\\n",
      "0                   27                  0                  0   \n",
      "1                    0                 11                  0   \n",
      "2                    0                 23                  7   \n",
      "3                    0                  2                  0   \n",
      "4                    6                 17                  0   \n",
      "..                 ...                ...                ...   \n",
      "784                  0                  0                  0   \n",
      "785                  0                  0                  0   \n",
      "786                  0                  0                  9   \n",
      "787                  0                  0                  0   \n",
      "788                  0                  2                  0   \n",
      "\n",
      "     metagenomics_1459  metagenomics_1460  metagenomics_1461  \\\n",
      "0                   18                  0                 16   \n",
      "1                   34                  0                  0   \n",
      "2                    0                  0                  0   \n",
      "3                    0                  0                  5   \n",
      "4                    2                  0                  0   \n",
      "..                 ...                ...                ...   \n",
      "784                  0                  0                 33   \n",
      "785                 29                  0                 27   \n",
      "786                  0                  6                  0   \n",
      "787                 11                  0                  7   \n",
      "788                  7                 29                 18   \n",
      "\n",
      "     metagenomics_1462  metagenomics_1463  \n",
      "0                    7                  0  \n",
      "1                   17                  0  \n",
      "2                    0                 24  \n",
      "3                    0                 24  \n",
      "4                    9                  0  \n",
      "..                 ...                ...  \n",
      "784                 17                  0  \n",
      "785                  0                 28  \n",
      "786                  0                  1  \n",
      "787                  0                  0  \n",
      "788                 11                  0  \n",
      "\n",
      "[789 rows x 1464 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_bad = pd.read_csv('./data/baseline_metagenomics.tsv', sep='\\t', header=0)\n",
    "file_good = pd.read_csv('./data/baseline_untarget_metabolomics.tsv', sep='\\t', header=0)\n",
    "print(file_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID  untargeted_metabolomics_1  untargeted_metabolomics_2  \\\n",
      "0      0                         13                          0   \n",
      "1      1                         19                          5   \n",
      "2      2                         17                          6   \n",
      "3      3                          7                         14   \n",
      "4      4                         13                          0   \n",
      "..   ...                        ...                        ...   \n",
      "784  784                          8                          0   \n",
      "785  785                          4                          0   \n",
      "786  786                         12                          9   \n",
      "787  787                         13                         12   \n",
      "788  788                          9                         12   \n",
      "\n",
      "     untargeted_metabolomics_3  untargeted_metabolomics_4  \\\n",
      "0                            0                          7   \n",
      "1                            0                          0   \n",
      "2                           15                          0   \n",
      "3                            0                         14   \n",
      "4                            0                         14   \n",
      "..                         ...                        ...   \n",
      "784                          0                         22   \n",
      "785                          1                          4   \n",
      "786                          1                          0   \n",
      "787                          7                          0   \n",
      "788                          0                          0   \n",
      "\n",
      "     untargeted_metabolomics_5  untargeted_metabolomics_6  \\\n",
      "0                            7                         10   \n",
      "1                           15                         14   \n",
      "2                           12                          4   \n",
      "3                            6                          0   \n",
      "4                            0                         10   \n",
      "..                         ...                        ...   \n",
      "784                         20                         10   \n",
      "785                          6                         25   \n",
      "786                          0                         11   \n",
      "787                          0                          0   \n",
      "788                         13                          0   \n",
      "\n",
      "     untargeted_metabolomics_7  untargeted_metabolomics_8  \\\n",
      "0                           13                          0   \n",
      "1                            6                          5   \n",
      "2                            0                          7   \n",
      "3                            6                         12   \n",
      "4                            7                          0   \n",
      "..                         ...                        ...   \n",
      "784                          0                          0   \n",
      "785                          0                          0   \n",
      "786                          0                         13   \n",
      "787                          0                          0   \n",
      "788                          3                          9   \n",
      "\n",
      "     untargeted_metabolomics_9  ...  untargeted_metabolomics_229  \\\n",
      "0                            0  ...                           18   \n",
      "1                            6  ...                           12   \n",
      "2                            0  ...                            1   \n",
      "3                            4  ...                           13   \n",
      "4                           14  ...                            0   \n",
      "..                         ...  ...                          ...   \n",
      "784                          0  ...                           13   \n",
      "785                         20  ...                            5   \n",
      "786                          7  ...                            0   \n",
      "787                          0  ...                           12   \n",
      "788                         16  ...                           11   \n",
      "\n",
      "     untargeted_metabolomics_230  untargeted_metabolomics_231  \\\n",
      "0                              7                            8   \n",
      "1                             16                           10   \n",
      "2                             12                           10   \n",
      "3                              0                            0   \n",
      "4                              0                           10   \n",
      "..                           ...                          ...   \n",
      "784                            7                            0   \n",
      "785                           14                            0   \n",
      "786                           14                            9   \n",
      "787                            0                            0   \n",
      "788                            0                            1   \n",
      "\n",
      "     untargeted_metabolomics_232  untargeted_metabolomics_233  \\\n",
      "0                             11                            0   \n",
      "1                              0                            0   \n",
      "2                              0                           11   \n",
      "3                              0                            6   \n",
      "4                              0                           21   \n",
      "..                           ...                          ...   \n",
      "784                            0                            0   \n",
      "785                           11                            3   \n",
      "786                            0                            0   \n",
      "787                           11                           16   \n",
      "788                            0                           19   \n",
      "\n",
      "     untargeted_metabolomics_234  untargeted_metabolomics_235  \\\n",
      "0                             12                           10   \n",
      "1                             17                            6   \n",
      "2                              2                            0   \n",
      "3                              0                            0   \n",
      "4                              9                           23   \n",
      "..                           ...                          ...   \n",
      "784                            0                           10   \n",
      "785                           10                            8   \n",
      "786                            0                            8   \n",
      "787                            0                            0   \n",
      "788                            0                           10   \n",
      "\n",
      "     untargeted_metabolomics_236  untargeted_metabolomics_237  \\\n",
      "0                              0                           19   \n",
      "1                             11                            1   \n",
      "2                             11                            7   \n",
      "3                              0                            2   \n",
      "4                              0                           10   \n",
      "..                           ...                          ...   \n",
      "784                            8                           12   \n",
      "785                            8                            6   \n",
      "786                            0                            0   \n",
      "787                            9                           14   \n",
      "788                           11                            8   \n",
      "\n",
      "     untargeted_metabolomics_238  \n",
      "0                              9  \n",
      "1                              4  \n",
      "2                              7  \n",
      "3                              0  \n",
      "4                              0  \n",
      "..                           ...  \n",
      "784                            9  \n",
      "785                            0  \n",
      "786                            2  \n",
      "787                            0  \n",
      "788                            6  \n",
      "\n",
      "[789 rows x 239 columns]\n"
     ]
    }
   ],
   "source": [
    "print(file_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for encoding\n",
    "\n",
    "def encode_cat(raw_input, num_classes=None, uniques=None, na='NA'):\n",
    "   matrix = np.array(raw_input)\n",
    "   n_labels = matrix.shape[1]\n",
    "   n_samples = matrix.shape[0]\n",
    "   \n",
    "   # make endocding dict\n",
    "   encodings = defaultdict(dict)\n",
    "   count = 0\n",
    "   no_unique = 0\n",
    "   \n",
    "   if uniques is None:\n",
    "      no_unique = 1\n",
    "      encodings = defaultdict(dict)\n",
    "      for lab in range(0,n_labels):\n",
    "         uniques = np.unique(matrix[:,lab])\n",
    "         uniques = sorted(uniques)\n",
    "         num_classes = len(uniques[uniques != na])\n",
    "         count = 0\n",
    "         for u in uniques:\n",
    "            if u == na:\n",
    "               encodings[lab][u] = np.zeros(num_classes)\n",
    "               continue\n",
    "            encodings[lab][u] = np.zeros(num_classes)\n",
    "            encodings[lab][u][count] = 1\n",
    "            count += 1\n",
    "   else:\n",
    "      for u in uniques:\n",
    "         if u == na:\n",
    "            encodings[u] = np.zeros(num_classes)\n",
    "            continue\n",
    "         encodings[u] = np.zeros(num_classes)\n",
    "         encodings[u][count] = 1\n",
    "         count += 1\n",
    "   \n",
    "   # encode the data\n",
    "   data_input = np.zeros((n_samples,n_labels,num_classes))\n",
    "   i = 0\n",
    "   for patient in matrix:\n",
    "      \n",
    "      data_sparse = np.zeros((n_labels, num_classes))\n",
    "      \n",
    "      count = 0\n",
    "      for lab in patient:\n",
    "         if no_unique == 1:\n",
    "            data_sparse[count] = encodings[count][lab]\n",
    "         else:\n",
    "            if lab != na:\n",
    "               lab = int(float(lab))\n",
    "            data_sparse[count] = encodings[lab]\n",
    "         count += 1\n",
    "      \n",
    "      data_input[i] = data_sparse\n",
    "      i += 1\n",
    "      \n",
    "   return data_input\n",
    "\n",
    "def encode_con(raw_input):\n",
    "   \n",
    "   matrix = np.array(raw_input)\n",
    "   \n",
    "   consum = matrix.sum(axis=1)\n",
    "   \n",
    "   data_input = np.log2(matrix + 1)\n",
    "   \n",
    "   # remove 0 variance\n",
    "   std = np.nanstd(data_input, axis=0)\n",
    "   mask_col = std != 0\n",
    "   data_input = data_input[:,mask_col]\n",
    "   # z-score normalize\n",
    "   mean = np.nanmean(data_input, axis=0)\n",
    "   \n",
    "   std = np.nanstd(data_input, axis=0)\n",
    "   \n",
    "   data_input = data_input  #check: data_input=data_input\n",
    "   data_input -= mean\n",
    "   data_input /= std\n",
    "   return data_input, mask_col  # Added return function\n",
    "\n",
    "def sort_data(data, ids, labels):\n",
    "   n_labels = len(labels)\n",
    "   sorted_data = list()\n",
    "   for ids in ids: #check: ids/ids\n",
    "      if ids in data:\n",
    "         sorted_data.append(data[ids])\n",
    "      else:\n",
    "         #tmp = np.zeros((n_labels))\n",
    "         #tmp[:] = np.nan\n",
    "         tmp = [0]*n_labels\n",
    "         sorted_data.append(tmp)\n",
    "        \n",
    "   return sorted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For encoding the data you need to have each dataset/data type in a format for N x M, where N is the numer of samples/individuals and M is the number of features. For using the dataset specific weighting in the training of the VAE you need to process the datasets individually or split them when you read them in. The continuous data is z-score normalised and the categorical data is one-hot encoded. Below is an example of processing a continuous dataset and two categorical datasets with different number of categories. To ensure the correct order the ID's are used for sorting the data accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_con_file(data_type):\n",
    "    ids = list()\n",
    "    with open(path + \"data/baseline_ids.txt\", \"r\") as f:\n",
    "        for line in f:\n",
    "            ids.append(line.rstrip())\n",
    "\n",
    "    # Encode continuous\n",
    "    raw_input = dict()\n",
    "    with open(path + f\"data/{data_type}.tsv\", \"r\") as f:\n",
    "        header = f.readline()\n",
    "        for line in f:\n",
    "            line = line.rstrip()\n",
    "            tmp = np.array(line.split(\"\\t\"))\n",
    "            vals = tmp[1:]\n",
    "            vals[vals == 'NA'] = np.nan\n",
    "            vals = list(map(float, vals))\n",
    "            raw_input[tmp[0]] = vals\n",
    "\n",
    "    header = header.split(\"\\t\")\n",
    "    sorted_data = sort_data(raw_input, ids, header)\n",
    "    data_input, mask = encode_con(sorted_data)\n",
    "    np.save(path + f\"data/{data_type}.npy\", sorted_data)\n",
    "\n",
    "generate_con_file('baseline_continuous')\n",
    "generate_con_file('baseline_transcriptomics')\n",
    "generate_con_file('baseline_diet_wearables')\n",
    "generate_con_file('baseline_proteomic_antibodies')\n",
    "generate_con_file('baseline_target_metabolomics')\n",
    "generate_con_file('baseline_untarget_metabolomics')\n",
    "generate_con_file('baseline_metagenomics')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cat_file(data_type, num_classes): #Todo make separate get IDs\n",
    "    ids = list()\n",
    "    with open(path + \"data/baseline_ids.txt\", \"r\") as f:\n",
    "        for line in f:\n",
    "            ids.append(line.rstrip()) \n",
    "             \n",
    "    raw_input = list()\n",
    "    with open(path + f\"data/{data_type}.tsv\", \"r\") as f:\n",
    "        header = f.readline()\n",
    "        for line in f:\n",
    "            line = line.rstrip()\n",
    "            tmp = line.split(\"\\t\")\n",
    "            raw_input.append(tmp[1:])\n",
    "\n",
    "    header = header.split(\"\\t\")\n",
    "\n",
    "    # Set the number of classes and categories\n",
    "    \n",
    "    if num_classes==2:\n",
    "        uniques = [0, 1, 'nan']\n",
    "    elif num_classes==3:\n",
    "        uniques = [0, 1, 2, 'nan']\n",
    "\n",
    "    # Sort and encode the data\n",
    "    sorted_data = sort_data(raw_input, ids, header)\n",
    "    data_input = encode_cat(sorted_data, num_classes, uniques, 'nan')\n",
    "    np.save(path + f\"data/{data_type}.npy\", data_input)\n",
    "    \n",
    "generate_cat_file('diabetes_genotypes', 3)\n",
    "generate_cat_file('baseline_drugs', 2)\n",
    "generate_cat_file('baseline_categorical', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get ids to sort the data\n",
    "ids = list()\n",
    "with open(path + \"data/baseline_ids.txt\", \"r\") as f:\n",
    "   for line in f:\n",
    "      ids.append(line.rstrip())\n",
    "        \n",
    "# Encode continuous\n",
    "raw_input = dict()\n",
    "with open(path + \"data/baseline_transcriptomics.tsv\", \"r\") as f:\n",
    "   header = f.readline()\n",
    "   for line in f:\n",
    "      line = line.rstrip()\n",
    "      tmp = np.array(line.split(\"\\t\"))\n",
    "      vals = tmp[1:]\n",
    "      vals[vals == 'NA'] = np.nan\n",
    "      vals = list(map(float, vals))\n",
    "      raw_input[tmp[0]] = vals\n",
    "#       break # added\n",
    "     \n",
    "header = header.split(\"\\t\")\n",
    "sorted_data = sort_data(raw_input, ids, header)\n",
    "data_input, mask = encode_con(sorted_data)\n",
    "np.save(path + \"data/baseline_transcriptomics.npy\", sorted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical data with two categories\n",
    "raw_input = list()\n",
    "with open(path + \"data/baseline_drugs.tsv\", \"r\") as f:\n",
    "   header = f.readline()\n",
    "   for line in f:\n",
    "      line = line.rstrip()\n",
    "      tmp = line.split(\"\\t\")\n",
    "      raw_input.append(tmp[1:])\n",
    "\n",
    "header = header.split(\"\\t\")\n",
    "\n",
    "# Set the number of classes and categories\n",
    "num_classes = 2\n",
    "uniques = [0, 1, 'nan']\n",
    "\n",
    "# Sort and encode the data\n",
    "sorted_data = sort_data(raw_input, ids, header)\n",
    "data_input = encode_cat(sorted_data, num_classes, uniques, 'nan')\n",
    "np.save(path + \"data/baseline_drugs.npy\", data_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical data with three categories\n",
    "raw_input = list()\n",
    "with open(path + \"data/diabetes_genotypes.tsv\", \"r\") as f:\n",
    "   header = f.readline()\n",
    "   for line in f:\n",
    "      line = line.rstrip()\n",
    "      tmp = line.split(\"\\t\")\n",
    "      raw_input.append(tmp[1:])\n",
    "\n",
    "\n",
    "header = header.split(\"\\t\")\n",
    "\n",
    "# Set the number of classes and categories\n",
    "num_classes = 3\n",
    "uniques = [0, 1, 2, 'nan']\n",
    "\n",
    "# Sort and encode the data\n",
    "sorted_data = sort_data(raw_input, ids, header)\n",
    "data_input = encode_cat(sorted_data, num_classes, uniques, 'nan')\n",
    "np.save(path + \"data/diabetes_genotypes.npy\", data_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
