{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode data\n",
    "\n",
    "This notebook runs part of the Multi-Omics Variational autoEncoder (MOVE) framework for using the structure the VAE has identified for extracting categorical data assositions across all continuous datasets. In the MOVE paper we used it for identifiying drug assosiations in clinical and multi-omics data. This part is a guide for encoding the data that can be used as input in MOVE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions\n",
    "from hydra import initialize, compose\n",
    "\n",
    "from move.utils.data_utils import read_ids, generate_file, merge_configs \n",
    "from move.utils.logger import get_logger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook merges user-defined configs in data.yaml file with default configs and override it. Then reads the needed variables.  \\\n",
    "For encoding the data you need to have each dataset/data type in a format for N x M, where N is the numer of samples/individuals and M is the number of features. For using the dataset specific weighting in the training of the VAE you need to process the datasets individually or split them when you read them in. The continuous data is z-score normalised and the categorical data is one-hot encoded. Below is an example of processing a continuous and categorical datasets. To ensure the correct order the ID's are used for sorting the data accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the default config \n",
    "with initialize(version_base=None, config_path=\"../src/move/conf\"):\n",
    "    base_config = compose(config_name=\"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO    root         \n",
      "\n",
      "---------------- Starting running the script ---------------\n",
      "INFO    data_utils   Overriding the default config with configs from data.yaml\n",
      "INFO    data_utils   \n",
      "\n",
      "Configuration used:\n",
      "data:\n",
      "  user_config: data.yaml\n",
      "  na_value: na\n",
      "  raw_data_path: data/\n",
      "  interim_data_path: interim_data/\n",
      "  processed_data_path: processed_data/\n",
      "  headers_path: headers/\n",
      "  version: v1\n",
      "  ids_file_name: baseline_ids.txt\n",
      "  ids_has_header: false\n",
      "  ids_colname: 0\n",
      "  categorical_inputs:\n",
      "  - name: diabetes_genotypes\n",
      "    weight: 1\n",
      "  - name: baseline_drugs\n",
      "    weight: 1\n",
      "  - name: baseline_categorical\n",
      "    weight: 1\n",
      "  continuous_inputs:\n",
      "  - name: baseline_continuous\n",
      "    weight: 2\n",
      "  - name: baseline_transcriptomics\n",
      "    weight: 1\n",
      "  - name: baseline_diet_wearables\n",
      "    weight: 1\n",
      "  - name: baseline_proteomic_antibodies\n",
      "    weight: 1\n",
      "  - name: baseline_target_metabolomics\n",
      "    weight: 1\n",
      "  - name: baseline_untarget_metabolomics\n",
      "    weight: 1\n",
      "  - name: baseline_metagenomics\n",
      "    weight: 1\n",
      "  data_of_interest: baseline_drugs\n",
      "  categorical_names: ${names:${data.categorical_inputs}}\n",
      "  continuous_names: ${names:${data.continuous_inputs}}\n",
      "  categorical_weights: ${weights:${data.categorical_inputs}}\n",
      "  continuous_weights: ${weights:${data.continuous_inputs}}\n",
      "  data_features_to_visualize_notebook4:\n",
      "  - drug_1\n",
      "  - clinical_continuous_2\n",
      "  - clinical_continuous_3\n",
      "  write_omics_results_notebook5:\n",
      "  - baseline_target_metabolomics\n",
      "  - baseline_untarget_metabolomics\n",
      "\n",
      "INFO    __main__     Encoding categorical data\n",
      "INFO    data_utils     Encoded diabetes_genotypes\n",
      "INFO    data_utils     Encoded baseline_drugs\n",
      "INFO    data_utils     Encoded baseline_categorical\n",
      "INFO    __main__     Encoding continuous data\n",
      "INFO    data_utils     Encoded baseline_continuous\n",
      "INFO    data_utils     Encoded baseline_transcriptomics\n",
      "INFO    data_utils     Encoded baseline_diet_wearables\n",
      "INFO    data_utils     Encoded baseline_proteomic_antibodies\n",
      "INFO    data_utils     Encoded baseline_target_metabolomics\n",
      "INFO    data_utils     Encoded baseline_untarget_metabolomics\n",
      "INFO    data_utils     Encoded baseline_metagenomics\n"
     ]
    }
   ],
   "source": [
    "def main(base_config=base_config):\n",
    "        \n",
    "    # Making logger for data writing\n",
    "    logger = get_logger(logging_path='./log',\n",
    "                        file_name='01_encode_data.log',\n",
    "                        script_name=__name__)\n",
    "    \n",
    "    # Overriding base_config with the user defined configs.\n",
    "    cfg = merge_configs(base_config=base_config, \n",
    "                        config_types=['data'])\n",
    "    \n",
    "    # Getting the variables used in the notebook\n",
    "    raw_data_path = cfg.data.raw_data_path\n",
    "    interim_data_path = cfg.data.interim_data_path\n",
    "    headers_path = cfg.data.headers_path\n",
    "    \n",
    "    ids_file_name = cfg.data.ids_file_name\n",
    "    ids_has_header = cfg.data.ids_has_header\n",
    "    ids_colname = cfg.data.ids_colname\n",
    "    \n",
    "    na_encoding = cfg.data.na_value\n",
    "    categorical_names = cfg.data.categorical_names\n",
    "    continuous_names = cfg.data.continuous_names    \n",
    "    \n",
    "    # Reading ids \n",
    "    ids = read_ids(raw_data_path, ids_file_name, ids_colname, ids_has_header)\n",
    "\n",
    "    # Encoding categorical data\n",
    "    logger.info('Encoding categorical data')\n",
    "    for cat_data in categorical_names:\n",
    "        generate_file('categorical', raw_data_path, interim_data_path, headers_path, cat_data, ids, na_encoding)\n",
    "    \n",
    "    # Encoding continuous data \n",
    "    logger.info('Encoding continuous data')\n",
    "    for con_data in continuous_names:\n",
    "        generate_file('continuous', raw_data_path, interim_data_path, headers_path, con_data, ids, na_encoding)    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
